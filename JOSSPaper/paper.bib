@misc{ArcGIS,
author = "Arcgis",
  title = {{software}},
  howpublished = "\url{https://www.arcgis.com/index.html}", 
  year = "2017",
  note = "[Online]"
}

@misc{QGIS,
author = "Qgis",
  title = {{software}},
  howpublished = "\url{https://www.qgis.org/en/site/}", 
  year = "2017",
  note = "[Online]"
}

@misc{ENVI,
author = "Envi",
  title = {{software}},
  howpublished = "\url{https://www.esrij.com/products/envi}", 
  year = "2017",
  note = "[Online]"
}

@article{franti2019much,
  title={How much can k-means be improved by using better initialization and repeats?},
  author={Fr{\"a}nti, Pasi and Sieranoja, Sami},
  journal={Pattern Recognition},
  volume={93},
  pages={95--112},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{veena2024rasterminer,
  title={rasterMiner: An Open-Source Python Library to Discover Knowledge From Raster Imagery Data},
  author={Veena, Pamalla and Kiran, Rage Uday and Yoshiko, Ogawa and Makiko, Ohtake},
  booktitle={2024 IEEE Space, Aerospace and Defence Conference (SPACE)},
  pages={1160--1163},
  year={2024},
  organization={IEEE}
}

@misc{GeoAnalytics,
author = "Geoanalytics",
  title = {{Open Source}},
  howpublished = "\url{https://github.com/UdayLab/geoAnalytics}", 
  year = "2022",
  note = "[Online]"
}

@article{kMeans,
  added-at = {2011-01-11T13:34:58.000+0100},
  author = {Hartigan, J. A. and Wong, M. A.},
  biburl = {https://www.bibsonomy.org/bibtex/20399e12b4e411a03eda28ebaf11553ec/enitsirhc},
  interhash = {f32378f161e481db5375fe5164281ee9},
  intrahash = {0399e12b4e411a03eda28ebaf11553ec},
  journal = {JSTOR: Applied Statistics},
  keywords = {kmeans clustering},
  number = 1,
  pages = {100--108},
  timestamp = {2011-01-11T13:34:58.000+0100},
  title = {A k-means clustering algorithm},
  volume = 28,
  year = 1979
}

@inproceedings{kmeansPP,
author = {Arthur, David and Vassilvitskii, Sergei},
title = {k-means++: the advantages of careful seeding},
year = {2007},
isbn = {9780898716245},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
abstract = {The k-means method is a widely used clustering technique that seeks to minimize the average squared distance between points in the same cluster. Although it offers no accuracy guarantees, its simplicity and speed are very appealing in practice. By augmenting k-means with a very simple, randomized seeding technique, we obtain an algorithm that is Θ(logk)-competitive with the optimal clustering. Preliminary experiments show that our augmentation improves both the speed and the accuracy of k-means, often quite dramatically.},
booktitle = {Proceedings of the Eighteenth Annual ACM-SIAM Symposium on Discrete Algorithms},
pages = {1027–1035},
numpages = {9},
location = {New Orleans, Louisiana},
series = {SODA '07}
}

@inproceedings{dbscan,
author = {Ester, Martin and Kriegel, Hans-Peter and Sander, J\"{o}rg and Xu, Xiaowei},
title = {A density-based algorithm for discovering clusters in large spatial databases with noise},
year = {1996},
publisher = {AAAI Press},
abstract = {Clustering algorithms are attractive for the task of class identification in spatial databases. However, the application to large spatial databases rises the following requirements for clustering algorithms: minimal requirements of domain knowledge to determine the input parameters, discovery of clusters with arbitrary shape and good efficiency on large databases. The well-known clustering algorithms offer no solution to the combination of these requirements. In this paper, we present the new clustering algorithm DBSCAN relying on a density-based notion of clusters which is designed to discover clusters of arbitrary shape. DBSCAN requires only one input parameter and supports the user in determining an appropriate value for it. We performed an experimental evaluation of the effectiveness and efficiency of DBSCAN using synthetic data and real data of the SEQUOIA 2000 benchmark. The results of our experiments demonstrate that (1) DBSCAN is significantly more effective in discovering clusters of arbitrary shape than the well-known algorithm CLAR-ANS, and that (2) DBSCAN outperforms CLARANS by a factor of more than 100 in terms of efficiency.},
booktitle = {Proceedings of the Second International Conference on Knowledge Discovery and Data Mining},
pages = {226–231},
numpages = {6},
keywords = {efficiency on large spatial databases, clustering algorithms, arbitrary shape of clusters, handling nlj4-275oise},
location = {Portland, Oregon},
series = {KDD'96}
}

@inproceedings{spectralClustering,
author = {Ng, Andrew Y. and Jordan, Michael I. and Weiss, Yair},
title = {On spectral clustering: analysis and an algorithm},
year = {2001},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
abstract = {Despite many empirical successes of spectral clustering methods— algorithms that cluster points using eigenvectors of matrices derived from the data—there are several unresolved issues. First. there are a wide variety of algorithms that use the eigenvectors in slightly different ways. Second, many of these algorithms have no proof that they will actually compute a reasonable clustering. In this paper, we present a simple spectral clustering algorithm that can be implemented using a few lines of Matlab. Using tools from matrix perturbation theory, we analyze the algorithm, and give conditions under which it can be expected to do well. We also show surprisingly good experimental results on a number of challenging clustering problems.},
booktitle = {Proceedings of the 15th International Conference on Neural Information Processing Systems: Natural and Synthetic},
pages = {849–856},
numpages = {8},
location = {Vancouver, British Columbia, Canada},
series = {NIPS'01}
}

@inproceedings{fuzzyTimeSeriesClassifier,
  author       = {Penugonda Ravikumar and
                  R. Uday Kiran and
                  Narendra Babu Unnam and
                  Yutaka Watanobe and
                  Kazuo Goda and
                  V. Susheela Devi and
                  P. Krishna Reddy},
  title        = {A Novel Parameter-Free Energy Efficient Fuzzy Nearest Neighbor Classifier
                  for Time Series Data},
  booktitle    = {30th {IEEE} International Conference on Fuzzy Systems, {FUZZ-IEEE}
                  2021, Luxembourg, July 11-14, 2021},
  pages        = {1--6},
  publisher    = {{IEEE}},
  year         = {2021},
  url          = {https://doi.org/10.1109/FUZZ45933.2021.9494521},
  doi          = {10.1109/FUZZ45933.2021.9494521},
  timestamp    = {Tue, 10 Aug 2021 09:25:09 +0200},
  biburl       = {https://dblp.org/rec/conf/fuzzIEEE/RavikumarKUWGDR21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{dtw,
author = {Berndt, Donald J. and Clifford, James},
title = {Using dynamic time warping to find patterns in time series},
year = {1994},
publisher = {AAAI Press},
abstract = {Knowledge discovery in databases presents many interesting challenges within the context of providing computer tools for exploring large data archives. Electronic data repositories are growing quickly and contain data from commercial, scientific, and other domains. Much of this data is inherently temporal, such as stock prices or NASA telemetry data. Detecting patterns in such data streams or time series is an important knowledge discovery task. This paper describes some preliminary experiments with a dynamic programming approach to the problem. The pattern detection algorithm is based on the dynamic time warping technique used in the speech recognition field.},
booktitle = {Proceedings of the 3rd International Conference on Knowledge Discovery and Data Mining},
pages = {359–370},
numpages = {12},
keywords = {dynamic programming, dynamic time warping, knowledge discovery, pattern analysis, time series},
location = {Seattle, WA},
series = {AAAIWS'94}
}

@inproceedings{partialPeriodicPatterns,
  author       = {R. Uday Kiran and
                  Haichuan Shang and
                  Masashi Toyoda and
                  Masaru Kitsuregawa},
  title        = {Discovering Partial Periodic Itemsets in Temporal Databases},
  booktitle    = {Proceedings of the 29th International Conference on Scientific and
                  Statistical Database Management, Chicago, IL, USA, June 27-29, 2017},
  pages        = {30:1--30:6},
  publisher    = {{ACM}},
  year         = {2017},
  url          = {https://doi.org/10.1145/3085504.3085535},
  doi          = {10.1145/3085504.3085535},
  timestamp    = {Sun, 19 Jan 2025 13:32:48 +0100},
  biburl       = {https://dblp.org/rec/conf/ssdbm/KiranSTK17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{frequentPatternMining,
author = {Han, Jiawei and Cheng, Hong and Xin, Dong and Yan, Xifeng},
title = {Frequent pattern mining: current status and future directions},
year = {2007},
issue_date = {August    2007},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {15},
number = {1},
issn = {1384-5810},
url = {https://doi.org/10.1007/s10618-006-0059-1},
doi = {10.1007/s10618-006-0059-1},
abstract = {Frequent pattern mining has been a focused theme in data mining research for over a decade. Abundant literature has been dedicated to this research and tremendous progress has been made, ranging from efficient and scalable algorithms for frequent itemset mining in transaction databases to numerous research frontiers, such as sequential pattern mining, structured pattern mining, correlation mining, associative classification, and frequent pattern-based clustering, as well as their broad applications. In this article, we provide a brief overview of the current status of frequent pattern mining and discuss a few promising research directions. We believe that frequent pattern mining research has substantially broadened the scope of data analysis and will have deep impact on data mining methodologies and applications in the long run. However, there are still some challenging research issues that need to be solved before frequent pattern mining can claim a cornerstone approach in data mining applications.},
journal = {Data Min. Knowl. Discov.},
month = aug,
pages = {55–86},
numpages = {32},
keywords = {Frequent pattern mining, Data mining research, Association rules, Applications}
}

@article{periodicFrequentPatternMining,
  author       = {R. Uday Kiran and
                  Masaru Kitsuregawa and
                  P. Krishna Reddy},
  title        = {Efficient discovery of periodic-frequent patterns in very large databases},
  journal      = {J. Syst. Softw.},
  volume       = {112},
  pages        = {110--121},
  year         = {2016},
  url          = {https://doi.org/10.1016/j.jss.2015.10.035},
  doi          = {10.1016/J.JSS.2015.10.035},
  timestamp    = {Mon, 24 Feb 2020 15:59:21 +0100},
  biburl       = {https://dblp.org/rec/journals/jss/KiranKR16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{pami,
  author       = {Rage Uday Kiran and
                  Pamalla Veena and
                  Masashi Toyoda and
                  Masaru Kitsuregawa},
  title        = {{PAMI:} An Open-Source Python Library for Pattern Mining},
  journal      = {J. Mach. Learn. Res.},
  volume       = {25},
  pages        = {209:1--209:6},
  year         = {2024},
  url          = {https://jmlr.org/papers/v25/22-1026.html},
  timestamp    = {Mon, 16 Sep 2024 17:07:54 +0200},
  biburl       = {https://dblp.org/rec/journals/jmlr/KiranVTK24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{li2020comparison,
  title={Comparison of several remote sensing image classification methods based on envi},
  author={Li, XC and Liu, LL and Huang, LK},
  journal={The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  volume={42},
  pages={605--611},
  year={2020},
  publisher={Copernicus GmbH}
}

@article{bennett2018machine,
  title={Machine learning in ArcGIS},
  author={Bennett, Lauren and Pobuda, Marjean},
  journal={ArcUser},
  volume={21},
  number={2},
  pages={8--9},
  year={2018}
}

@article{kramer2016scikit,
  title={Scikit-learn},
  author={Kramer, Oliver and Kramer, Oliver},
  journal={Machine learning for evolution strategies},
  pages={45--53},
  year={2016},
  publisher={Springer}
}

@article{developers2022tensorflow,
  title={TensorFlow},
  author={Developers, TensorFlow},
  journal={Zenodo},
  year={2022}
}

@article{zhang2016missing,
  title={Missing data imputation: focusing on single imputation},
  author={Zhang, Zhongheng},
  journal={Annals of translational medicine},
  volume={4},
  number={1},
  pages={9},
  year={2016}
}

@incollection{rubin2018multiple,
  title={Multiple imputation},
  author={Rubin, Donald B},
  booktitle={Flexible imputation of missing data, second edition},
  pages={29--62},
  year={2018},
  publisher={Chapman and Hall/CRC}
}

@article{donders2006gentle,
  title={A gentle introduction to imputation of missing values},
  author={Donders, A Rogier T and Van Der Heijden, Geert JMG and Stijnen, Theo and Moons, Karel GM},
  journal={Journal of clinical epidemiology},
  volume={59},
  number={10},
  pages={1087--1091},
  year={2006},
  publisher={Elsevier}
}

@article{gillies2019rasterio,
  title={Rasterio documentation},
  author={Gillies, Sean},
  journal={MapBox: San Francisco, CA, USA},
  volume={23},
  year={2019}
}